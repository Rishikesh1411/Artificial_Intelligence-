# ü§ñ Artificial Intelligence ‚Äì Notes Repository

This repository contains **structured written notes on Artificial Intelligence**.  
It is designed for **theory understanding, revision, and exam preparation**.


---

## üìñ Purpose of This Repository

- Maintain **well-organized AI notes**
- Provide **clear theoretical explanations**
- Help in **college exams, viva, and quick revision**
- Serve as a **personal knowledge base** for AI concepts

---

## üß† Topics Covered (Notes Only)

### 1Ô∏è‚É£ Introduction to Artificial Intelligence
- Definition of Artificial Intelligence
- History and evolution of AI
- Types of AI:
  - Narrow AI
  - General AI
  - Superintelligent AI
- Real-world applications of AI
- Overview of:
  - Machine Learning
  - Deep Learning
  - Natural Language Processing
  - Computer Vision
  - Generative AI
- Modern AI ecosystem:
  - Large Language Models (LLMs)
  - Multimodal AI systems

---

### 2Ô∏è‚É£ Machine Learning (ML)
- Definition of Machine Learning
- Types of learning:
  - Supervised learning
  - Unsupervised learning
  - Reinforcement learning
- Data preprocessing techniques
- Feature engineering
- Exploratory Data Analysis (EDA)
- Regression models
- Classification models
- Ensemble methods:
  - Bagging
  - Boosting
- Clustering techniques:
  - K-Means
  - DBSCAN
  - Hierarchical clustering
- Dimensionality reduction:
  - PCA
  - LDA
  - t-SNE
- Model evaluation metrics
- Overfitting & underfitting
- Bias‚ÄìVariance tradeoff
- Hyperparameter tuning

---

### 3Ô∏è‚É£ Deep Learning (DL)
- Introduction to neural networks
- Perceptron model
- Activation functions
- Backpropagation algorithm
- Fully Connected Neural Networks (ANN)
- Convolutional Neural Networks (CNN)
- Recurrent Neural Networks (RNN)
- Long Short-Term Memory (LSTM)
- Gated Recurrent Units (GRU)
- Graph Neural Networks (GNN)
- Transformer architecture
- Attention mechanism
- Generative models:
  - GANs
  - Diffusion models
- Loss functions
- Optimizers
- Regularization techniques

---

### 4Ô∏è‚É£ Natural Language Processing (NLP)
- Classical NLP concepts:
  - Tokenization
  - Stopword removal
  - Stemming
  - Lemmatization
- Text vectorization:
  - Bag of Words
  - TF-IDF
- Word embeddings:
  - Word2Vec
  - GloVe
- Sequence models:
  - RNN
  - LSTM
  - GRU
- Attention & contextual representation
- Transformer-based models:
  - BERT
  - GPT
  - T5
- NLP tasks:
  - Named Entity Recognition (NER)
  - Question Answering
  - Text Summarization
  - Machine Translation
- Prompt engineering concepts
- Common NLP libraries (theoretical overview)

---

### 5Ô∏è‚É£ Computer Vision (CV)
- Basics of computer vision
- Image representation & pixels
- Convolution operations
- Filters and feature extraction
- Traditional CV techniques:
  - SIFT
  - HOG
- Object detection overview:
  - R-CNN
  - YOLO
  - DETR
- Image segmentation:
  - U-Net
  - Mask R-CNN
- Face detection & recognition concepts
- Vision Transformer (ViT)

---

### 6Ô∏è‚É£ Transfer Learning & Fine-Tuning
- Concept of pretrained models
- Transfer learning principles
- Fine-tuning strategies:
  - Full fine-tuning
  - Adapter-based tuning
  - LoRA / QLoRA
- Prompt-tuning vs fine-tuning
- Use cases of transfer learning

---

### 7Ô∏è‚É£ Retrieval-Augmented Generation (RAG)
- Motivation behind RAG
- RAG architecture
- Embedding & indexing concepts
- Retrieval mechanism
- Generation step
- Chunking strategies
- Vector databases (conceptual overview)
- Comparison:
  - RAG vs fine-tuning

---

### 8Ô∏è‚É£ Speech AI
- Automatic Speech Recognition (ASR)
- Text-to-Speech (TTS)
- Speaker identification
- Emotion recognition
- Voice assistant architecture
- Multimodal speech + language systems

---

### 9Ô∏è‚É£ Graph Neural Networks (GNNs)
- Graph data representation
- Nodes, edges & adjacency matrices
- Message passing framework
- Graph convolution
- Graph embeddings
- GNN architectures:
  - GCN
  - GAT
  - GraphSAGE
  - R-GCN
- Applications of GNNs
- Common GNN tools (theory-focused)

---

### üîü Advanced AI Topics
- DETR architecture
- Multimodal AI
- Decoding strategies
- Mixture of Experts (MoE)
- Large Language Models (LLMs):
  - Architecture
  - Training concepts
  - Applications

---

### 1Ô∏è‚É£1Ô∏è‚É£ Vision‚ÄìLanguage Models (VLMs)
- Introduction to VLMs
- CLIP
- GroundingDINO
- Segment Anything Model (SAM)
- Vision-language workflows
- Practical applications

---

### 1Ô∏è‚É£2Ô∏è‚É£ AI Explainability
- Explainable AI (XAI)
- Need for interpretability
- Grad-CAM
- Attention visualization

---

## üìÇ Repository Structure


---

## üìå How to Use These Notes

- Read sequentially for **concept building**
- Use for **quick revision before exams**
- Refer during **project planning**
- Helpful for **viva and interviews**

---

## üìú Disclaimer

These notes are created for **educational and self-learning purposes**.  
Content is compiled from standard AI concepts and academic references.

---

## üôå Author

**Rishikesh Raj**  
üìò Artificial Intelligence Notes Repository

---

‚≠ê *If these notes help you, consider starring the repository.*

